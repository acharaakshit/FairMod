{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import fairness_metrics\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideology_df = pd.read_csv('./data/processed_annotated_comments.csv')\n",
    "ideology_df['label'] = ideology_df['label'].apply(lambda x: None if x not in ['left', 'right'] else x)\n",
    "ideology_df.dropna(inplace=True)\n",
    "\n",
    "main_df = pd.read_csv('./data/jigsaw/main.csv')\n",
    "dfs = [ideology_df, main_df] \n",
    "names = ['ideology', 'jigsaw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed results\n",
    "with open('./results/moderation_results.pkl', 'rb') as file:\n",
    "    fairness_results = pickle.load(file)\n",
    "\n",
    "\n",
    "gold1 = {k:v['openai'] for k,v in fairness_results.items()}\n",
    "gold2 = {k:v['perspective'] for k,v in fairness_results.items()}\n",
    "gold3 = {k:v['google'] for k,v in fairness_results.items() if v['google'] in [True, False]}\n",
    "gold4 = {k:v['clarifai'] for k,v in fairness_results.items()}\n",
    "\n",
    "gold1 = {k: 1 if v is True else 0 for k,v in gold1.items()}\n",
    "gold2 = {k: 1 if v is True else 0 for k,v in gold2.items()}\n",
    "gold3 = {k:1 if v is True else 0 for k,v in gold3.items()}\n",
    "gold4 = {k:1 if v is True else 0 for k,v in gold4.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_percentage_change(main_list, list1):\n",
    "    indices_unsafe = [i for i, x in tqdm(enumerate(main_list)) if x == 'UNSAFE']\n",
    "    indices_safe = [i for i, x in tqdm(enumerate(main_list)) if x == 'SAFE']\n",
    "    indices_map = {'UNSAFE': indices_unsafe, 'SAFE': indices_safe}\n",
    "\n",
    "    category_map = {\n",
    "                    'UNSAFE': {'UNSAFE': [], 'SAFE': []},\n",
    "                    'SAFE': {'UNSAFE': [], 'SAFE': []}\n",
    "                    }\n",
    "    for k, v in category_map.items():\n",
    "        for subk, subv in v.items():\n",
    "            category_map[k][subk] = [l for idx, l in tqdm(enumerate(list1)) if idx in indices_map[k] and l == subk]\n",
    "            category_map[k][subk] = len(category_map[k][subk])/len(indices_map[k])\n",
    "\n",
    "    return category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golds = [gold1, gold2, gold3, gold4]\n",
    "\n",
    "methods = ['openai', 'perspective','google', 'clarifai']\n",
    "perturbations = ['german', 'gpt_3.5_turbo']\n",
    "\n",
    "results = []\n",
    "global_results = {}\n",
    "\n",
    "perturbation_map = {}\n",
    "with open('./results/comments_backtranslated_german_similarity.pkl', 'rb') as handle:\n",
    "        perturbation_map[perturbations[0]] = pickle.load(handle)\n",
    "\n",
    "with open('./results/comment_paraphrased_gpt-3.5_final.pkl', 'rb') as handle:\n",
    "        perturbation_map[perturbations[1]] = pickle.load(handle)\n",
    "\n",
    "for method in methods:\n",
    "    global_results[method] = {}\n",
    "\n",
    "for perturbation in perturbations:\n",
    "    with open(f'./results/moderation_results_fairness_perturbed_{perturbation}.pkl', 'rb') as handle:\n",
    "        fairness_results = pickle.load(handle)\n",
    "    \n",
    "    phrase_map = perturbation_map[perturbation]\n",
    "    if perturbation == \"german\":\n",
    "        phrase_map = {k:v['augmented'] for k,v in phrase_map.items() if v['score'] > 0.85 and v['score'] != 1.0}\n",
    "\n",
    "    for gold, method in zip(golds, methods):\n",
    "        local_gold = gold.copy()\n",
    "        \n",
    "        # check to ignore NULL values for phrases where moderation did not run\n",
    "        fairness_results = {k:v for k,v in fairness_results.items() if fairness_results[k][method] in [True, False]}\n",
    "        \n",
    "        data = {k:int(fairness_results[v][method]) for k,v in phrase_map.items() if v in fairness_results.keys()}\n",
    "\n",
    "        local_gold = {k:v for k,v in local_gold.items() if k in data.keys() and v in [True, False]}\n",
    "\n",
    "        # create lists and compute robustness\n",
    "        global_results[method][perturbation] = {}\n",
    "        for subset, name in zip(dfs, names):\n",
    "            df = subset.copy()\n",
    "            df = df[df['text'].isin(list(local_gold.keys()))]\n",
    "            a = ['UNSAFE' if local_gold[k] == 1 else 'SAFE' for k in df['text'].tolist()]\n",
    "            b = ['UNSAFE' if data[k] == 1 else 'SAFE' for k in df['text'].tolist()]\n",
    "            change_map = compute_percentage_change(a, b)\n",
    "            global_results[method][perturbation][name] = change_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "labels = ['UNSAFE', 'SAFE']\n",
    "titles = ['OpenAI', 'Perspective', 'PaLM2', 'Clarifai']\n",
    "\n",
    "data=[v['gpt_3.5_turbo']['jigsaw'] for k,v in global_results.items()]\n",
    "data = [data[0], data[3], data[1], data[2]]\n",
    "\n",
    "\n",
    "heatmap_data = [np.zeros((2,2)) for _ in range(len(data))]\n",
    "\n",
    "global_max = -np.inf\n",
    "global_min = np.inf\n",
    "\n",
    "for i, row in enumerate(data):\n",
    "    for j, col in enumerate(row.values()):\n",
    "        for k, val in enumerate(col.values()):\n",
    "            heatmap_data[i][j, k] = val\n",
    "            if val > global_max:\n",
    "                global_max = val\n",
    "            if val < global_min:\n",
    "                global_min = val\n",
    "\n",
    "fig, axes = plt.subplots(1, len(data), figsize=(15,3), sharey=True)\n",
    "fig.subplots_adjust(wspace=0.01)\n",
    "for i, ax in enumerate(axes):\n",
    "    sns.heatmap(heatmap_data[i], annot=True, fmt=\".2f\", cmap=\"crest\", xticklabels=labels, yticklabels=labels, ax=ax, annot_kws={\"size\":16}, vmin=global_min, vmax=global_max, cbar=False)\n",
    "    ax.set_title(titles[i], fontsize=20)\n",
    "    ax.xaxis.set_tick_params(labelsize=20)\n",
    "    ax.yaxis.set_tick_params(labelsize=20)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\")\n",
    "\n",
    "cbar = fig.colorbar(axes[0].collections[0], ax=axes, orientation='vertical')\n",
    "cbar.set_label('Change (%)')\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "cbar.ax.yaxis.label.set_size(12)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
